use polars::prelude::*;
use std::fs;
use std::path::{Path, PathBuf};

// ç»™ Polars è¿›è¡Œæ‰©å±•, è®©å®ƒå˜å¾—å¥½ç”¨
pub enum Format {
    Csv,
    Parquet,
    Json,
}
trait PolarsEasy {
    /// ç®€å•ä¿å­˜åˆ°æ–‡ä»¶ï¼Œè‡ªåŠ¨è¯†åˆ« CSV/Parquet æ ¼å¼
    fn easy_sink<P: AsRef<Path>>(self, path: P) -> PolarsResult<()>;

    /// åˆ†åŒºä¿å­˜
    fn easy_sink_partition<P: AsRef<Path>>(
        self,
        dir: P,
        partition_cols: &[&str],
        format: Option<Format>,
    ) -> PolarsResult<()>;
}

impl PolarsEasy for LazyFrame {
    fn easy_sink<P: AsRef<Path>>(self, path: P) -> PolarsResult<()> {
        let path_ref = path.as_ref();
        let ext = path_ref
            .extension()
            .and_then(|e| e.to_str())
            .ok_or_else(|| {
                PolarsError::ComputeError(
                    "Cannot determine file type from path. Use .csv or .parquet".into(),
                )
            })?;
        let sink_target = SinkTarget::Path(PlPath::Local(Arc::from(path_ref)));
        match ext.to_lowercase().as_str() {
            "csv" => {
                let mut opt = CsvWriterOptions::default();
                opt.include_header = true;
                self.sink_csv(sink_target, opt, None, SinkOptions::default())?.collect()?
            }
            "parquet" => self.sink_parquet(
                sink_target,
                ParquetWriteOptions::default(),
                None,
                SinkOptions::default(),
            )?.collect()?,
            "json" => {
                self.sink_json(
                    sink_target,
                    JsonWriterOptions::default(),
                    None,
                    SinkOptions::default(),
                )?.collect()?
            }
            _ => unreachable!(),
        };
        Ok(())
    }

    fn easy_sink_partition<P: AsRef<Path>>(
        self,
        dir: P,
        partition_cols: &[&str],
        format: Option<Format>,
    ) -> PolarsResult<()> {
        let dir_path = dir.as_ref();

        if dir_path.is_file() {
            return Err(PolarsError::ComputeError(
                "Path is a file, not a directory".into(),
            ));
        }

        // å…ˆåˆ›å»ºç›®å½•
        fs::create_dir_all(dir_path).map_err(|e| {
            PolarsError::ComputeError(format!("Failed to create directory: {}", e).into())
        })?;

        // ğŸ”¥ è·å–è§„èŒƒåŒ–çš„ç»å¯¹è·¯å¾„ï¼ˆåœ¨ç›®å½•å­˜åœ¨åï¼‰
        let canonical_path = dir_path.canonicalize().map_err(|e| {
            PolarsError::ComputeError(
                format!(
                    "Failed to canonicalize path '{}': {}",
                    dir_path.display(),
                    e
                )
                .into(),
            )
        })?;

        eprintln!("ğŸ“ Canonical path: {}", canonical_path.display());

        if partition_cols.is_empty() {
            return Err(PolarsError::ComputeError(
                "partition_cols cannot be empty".into(),
            ));
        }

        match format {
            Some(Format::Csv) => {
                write_partitioned(self, canonical_path, partition_cols, Format::Csv)?;
            }
            _ => {
                write_partitioned(self, canonical_path, partition_cols, Format::Parquet)?;
                eprintln!("âœ… Parquet partition written");
            }
        }

        Ok(())
    }
}

// ğŸ”¥ æ ¸å¿ƒå‡½æ•°ï¼šæ‰‹åŠ¨åˆ†åŒºå¹¶å†™å…¥
/// æ‰‹åŠ¨å®ç°åˆ†åŒºå†™å…¥ï¼ˆæ”¯æŒ Parquet å’Œ CSVï¼‰
fn write_partitioned<P: AsRef<Path>>(
    lf: LazyFrame,
    base_path: P,
    partition_cols: &[&str],
    format: Format,
) -> PolarsResult<()> {
    let dir_path = base_path.as_ref();

    // åˆ›å»ºè¾“å‡ºç›®å½•
    fs::create_dir_all(dir_path).map_err(|e| {
        PolarsError::ComputeError(format!("Failed to create directory: {}", e).into())
    })?;

    // æ”¶é›†æ•°æ®
    eprintln!("ğŸ“Š Collecting data...");
    let df = lf.collect()?;
    eprintln!("âœ… Collected {} rows", df.height());

    if df.height() == 0 {
        eprintln!("âš ï¸  DataFrame is empty, nothing to write");
        return Ok(());
    }

    // æŒ‰åˆ†åŒºåˆ—åˆ†ç»„
    eprintln!("ğŸ” Grouping by partition columns: {:?}", partition_cols);
    let grouped = df.partition_by_stable(partition_cols.iter().cloned(), true)?;
    eprintln!("ğŸ“¦ Found {} partitions", grouped.len());

    // ä¸ºæ¯ä¸ªåˆ†ç»„å†™å…¥æ–‡ä»¶
    for (idx, mut partition_df) in grouped.into_iter().enumerate() {
        // æ„å»ºæ–‡ä»¶åï¼šcol1=value1_col2=value2
        let mut file_name_parts = Vec::new();

        for &col_name in partition_cols {
            let value = partition_df
                .column(col_name)?
                .get(0)?
                .to_string()
                .replace("\"", "") // ç§»é™¤å¼•å·
                .replace("/", "-") // æ›¿æ¢è·¯å¾„åˆ†éš”ç¬¦
                .replace("\\", "-")
                .replace(" ", "_"); // æ›¿æ¢ç©ºæ ¼

            file_name_parts.push(format!("{}={}", col_name, value));
        }

        // æ–‡ä»¶æ‰©å±•å
        let extension = match format {
            Format::Parquet => "parquet",
            Format::Csv => "csv",
            Format::Json => "json",
        };

        let file_name = format!("{}.{}", file_name_parts.join("_"), extension);
        let file_path = dir_path.join(&file_name);

        eprintln!("ğŸ’¾ Writing file: {}", file_path.display());

        // æ ¹æ®æ ¼å¼å†™å…¥æ–‡ä»¶
        let mut file = fs::File::create(&file_path).map_err(|e| {
            PolarsError::ComputeError(
                format!("Failed to create file '{}': {}", file_path.display(), e).into(),
            )
        })?;

        match format {
            Format::Parquet => {
                ParquetWriter::new(&mut file).finish(&mut partition_df)?;
            }
            Format::Csv => {
                CsvWriter::new(&mut file)
                    .include_header(true)
                    .finish(&mut partition_df)?;
            }
            Format::Json => {
                // ğŸ”¥ æ–°å¢ JSON æ”¯æŒ
                JsonWriter::new(&mut file)
                    .with_json_format(JsonFormat::JsonLines) // ä½¿ç”¨ JSON Lines æ ¼å¼
                    .finish(&mut partition_df)?;
            }
        }

        eprintln!("âœ… Written {} rows to {}", partition_df.height(), file_name);
    }

    eprintln!("ğŸ‰ All partitions written successfully!");
    Ok(())
}

pub fn load_csv_vec<P: AsRef<str>>(paths: Vec<P>) -> PolarsResult<LazyFrame> {
    let paths: Arc<[PlPath]> = paths
        .into_iter()
        .map(|v| PlPath::from_str(v.as_ref()))
        .collect();
    // ä½¿ç”¨æœ€é€šç”¨çš„å‚æ•°, é¿å…å¤æ‚, å¦‚æœä¸æ»¡è¶³éœ€æ±‚, è‡ªè¡Œè°ƒåº•å±‚ API å¤„ç†
    let lf = LazyCsvReader::new_paths(paths)
        .with_separator(b',')
        .with_has_header(true)
        .with_glob(false)
        .finish()?;
    Ok(lf)
}

// load_csv("data/*.csv");
// load_csv("data/***/*.csv");
pub fn load_csv<P: AsRef<Path>>(path: P) -> PolarsResult<LazyFrame> {
    let path = PlPath::Local(Arc::from(path.as_ref()));
    let lf = LazyCsvReader::new(path)
        .with_separator(b',')
        .with_has_header(true)
        .with_glob(true)
        .finish()?;
    Ok(lf)
}

// ğŸ”¥ æ–°å¢ï¼šåŠ è½½ JSON æ–‡ä»¶
/// åŠ è½½ JSON æ–‡ä»¶ï¼Œæ”¯æŒ glob æ¨¡å¼
/// ä¾‹å¦‚: load_json("data/*.json")
/// ä¾‹å¦‚: load_json("data/**/*.json")
pub fn load_json(path: &str) -> PolarsResult<LazyFrame> {
    // let args = ScanArgsAnonymous {
    //     infer_schema_length: Some(100),
    //     n_rows: None,
    //     row_index: None,
    //     ..Default::default()
    // };

    let lf = LazyJsonLineReader::new(PlPath::from_str(path))
        .finish()?;

    Ok(lf)
}

// å¼ºåˆ¶æ‰“å¼€ glob
// æ”¯æŒ load_parquet("data/*.parquet");
// æ”¯æŒ load_parquet("data/***/*.parquet");
fn load_parquet(path: &str, arg: Option<ScanArgsParquet>) -> PolarsResult<LazyFrame> {
    let mut arg = arg.unwrap_or_default();
    arg.glob = true;
    let lf = LazyFrame::scan_parquet(PlPath::from_str(path), arg)?;
    Ok(lf)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_csv() -> PolarsResult<()> {
        //let a = list_csv_files("../../data");
        //println!("{:?}", a);
        //
        let lf = load_csv_vec(vec![
            "../../data/stocks/002475.csv",
            "../../data/stocks/600000.csv",
            "../../data/stocks/603893.csv",
            "../../data/stocks/603986.csv",
        ])
        .unwrap();
        println!("{:?}", lf.collect().unwrap().height());

        let lf = load_csv("../../data/stocks/*.csv").unwrap();
        println!("{:?}", lf.collect().unwrap().height());
        Ok(())
    }

    #[test]
    fn test_parquet() -> PolarsResult<()> {
        let lf = load_parquet("../../tools/sina_news_parquet/2018.parquet", None).unwrap();
        // println!("2018 height: {:?}", lf.collect().unwrap().height());
        let cleaned = lf
            .with_column(
                col("pub_time")
                    .cast(DataType::Datetime(TimeUnit::Milliseconds, None))
                    .alias("datetime"),
            )
            .with_column(col("datetime").dt().strftime("%Y-%m").alias("year_month"))
            .with_column(col("datetime").dt().year().alias("year"))
            .with_column(col("datetime").dt().month().alias("month"));
        let lf_cleaned = cleaned.unique(Some(cols(["title"])), UniqueKeepStrategy::First);
        let result_df = lf_cleaned.collect().unwrap();
        // let r = result_df.lazy().easy_sink("./1.parquet").unwrap();
        result_df
            .lazy()
            .easy_sink_partition("./test-parquet-partition", &["year_month"], None)
            .unwrap();
        // result_df.lazy().easy_sink_partition("./test-csv-partition", &["year_month"], Some(PartitionFormat::Csv)).unwrap();
        Ok(())
    }

    #[test]
    fn test_parquet2() -> PolarsResult<()> {
        let df = df! {
            "year_month" => ["2018-07", "2018-08", "2018-07"],
            "value" => [1, 2, 3],
        }?;

        println!("DataFrame:\n{}", df);
        // æµå¼
        df.lazy().with_new_streaming(true).easy_sink_partition(
            "./test-parquet-partition",
            &["year_month"],
            None, // é»˜è®¤æ˜¯ Parquet
        )?;

        // éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»º
        assert!(Path::new("./test-parquet-partition").exists());

        Ok(())
    }

    #[test]
    fn test_json() -> PolarsResult<()> {
        // åˆ›å»ºæµ‹è¯•æ•°æ®
        let df = df! {
            "name" => ["Alice", "Bob", "Charlie"],
            "age" => [25, 30, 35],
            "city" => ["NY", "LA", "SF"],
        }?;

        // ä¿å­˜ä¸º JSON
        df.clone().lazy().easy_sink("./test_output.json").unwrap();

        // è¯»å– JSON
        let lf = load_json("./test_output.json").unwrap();
        let loaded_df = lf.collect().unwrap();

        println!("Loaded JSON DataFrame:\n{}", loaded_df);

        // æ¸…ç†æµ‹è¯•æ–‡ä»¶
        std::fs::remove_file("./test_output.json").ok();

        Ok(())
    }

    #[test]
    fn test_json_partition() -> PolarsResult<()> {
        let df = df! {
            "year_month" => ["2018-07", "2018-08", "2018-07"],
            "category" => ["A", "B", "A"],
            "value" => [1, 2, 3],
        }?;

        println!("DataFrame:\n{}", df);

        // åˆ†åŒºä¿å­˜ä¸º JSON
        df.lazy().easy_sink_partition(
            "./test-json-partition",
            &["year_month"],
            Some(Format::Json),
        )?;

        // éªŒè¯æ–‡ä»¶æ˜¯å¦åˆ›å»º
        assert!(Path::new("./test-json-partition").exists());

        // æ¸…ç†æµ‹è¯•ç›®å½•
        std::fs::remove_dir_all("./test-json-partition").ok();

        Ok(())
    }
}

// https://docs.pola.rs/user-guide/getting-started/#group_by
